{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pyHW1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GabrielMalinowski/GumtreeSpider/blob/master/pyHW1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "I5B77kdI5fUK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Getting Real Data from the Web"
      ]
    },
    {
      "metadata": {
        "id": "RNc4Sdgp5fUN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*Semestral Project*: build a statistical model from predicting real estate prices based on property features from data placed on ad site(s)"
      ]
    },
    {
      "metadata": {
        "id": "CnGOvxU85fUP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Curriculum\n",
        "\n",
        "## Getting the data\n",
        "### - Setting up the environement\n",
        "### - Anatomy of a Spider\n",
        "### - Anatomy of a Web Page\n",
        "### - Scrapy - a scraping framework\n",
        "### - Beautiful Soup\n",
        "### - Managing the Crawling Frontier\n",
        "### - Crawling Ethical Aspects \n",
        "## Processing the data\n",
        "### - Descriptive Analytics\n",
        "### - Feature Engineering\n",
        "### - Price Determining Factors\n",
        "## Price Prediction\n",
        "### - Training the model\n",
        "### - Model performance"
      ]
    },
    {
      "metadata": {
        "id": "BALLxFeX5fUQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*Spider* - a program that:\n",
        "- visits web pages from a list called *the frontier*\n",
        "- parses them to extract information - data and links\n",
        "- manages the _crawling frontier_ (links to be visited)"
      ]
    },
    {
      "metadata": {
        "id": "5qh0Boct5fUS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "https://packtpub.com/packt/offers/free-learning"
      ]
    },
    {
      "metadata": {
        "id": "KjCnbs1a5fUU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "https://docs.scrapy.org/en/latest/topics/spiders.html"
      ]
    },
    {
      "metadata": {
        "id": "Mm7_aIjO5fUV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You start by generating the initial Requests to crawl the first URLs, and specify a callback function to be called with the response downloaded from those requests.\n",
        "\n",
        "In the callback function, you parse the response (web page) and return either dicts with extracted data, Item objects, Request objects, or an iterable of these objects.\n",
        "\n",
        "In callback functions, you parse the page contents, typically using Selectors \n",
        "\n",
        "Finally, the items returned from the spider will be typically persisted to a database or written to a file\n"
      ]
    },
    {
      "metadata": {
        "id": "6oZNKqR65fUX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "import scrapy\n",
        "from scrapy.crawler import CrawlerProcess\n",
        "\n",
        "class PythonEventsSpider(scrapy.Spider):\n",
        "    name = 'pythoneventsspider'\n",
        "\n",
        "    start_urls = ['https://www.python.org/events/python-events/',]\n",
        "    found_events = []\n",
        "\n",
        "    def parse(self, response):\n",
        "        for event in response.xpath('//ul[contains(@class, \"list-recent-events\")]/li'):\n",
        "            event_details = dict()\n",
        "            event_details['name'] = event.xpath('h3[@class=\"event-title\"]/a/text()').extract_first()\n",
        "            event_details['location'] = event.xpath('p/span[@class=\"event-location\"]/text()').extract_first()\n",
        "            event_details['time'] = event.xpath('p/time/text()').extract_first()\n",
        "            self.found_events.append(event_details)\n",
        ">>> import re\n",
        ">>> re.sub(r'a', 'b', 'banana') (\\\\n|\\\\t)\n",
        "try:\n",
        "  print(x)\n",
        "except:\n",
        "  print(\"An exception occurred\")\n",
        "  'https://www.gumtree.pl/a-mieszkania-i-domy-sprzedam-i-kupie/srodmiescie/' + \\\n",
        "                  'lux-miodowa-przy-starym-miescie-metro-loggia/1004411332920910471374309'"
      ]
    },
    {
      "metadata": {
        "id": "5F10j5MM5fUY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "8a86c223-6b20-42f6-dda2-6863c675b76a"
      },
      "cell_type": "code",
      "source": [
        "import scrapy\n",
        "from scrapy.crawler import CrawlerProcess\n",
        "import re\n",
        "\n",
        "class PythonEventsSpider(scrapy.Spider):\n",
        "    name = 'pythoneventsspider'\n",
        "\n",
        "    start_urls = ['https://www.gumtree.pl/a-mieszkania-i-domy-sprzedam-i-kupie/srodmiescie/klimatyczne-mieszkanie-na-pieknej/1004479298810912110062609',]\n",
        "    found_events = []\n",
        "    \n",
        "    def parse(self, response):\n",
        "        \n",
        "        for event in response.xpath('//ul[contains(@class, \"selMenu\")]/li/div'):\n",
        "            event_details = dict()\n",
        "            try:\n",
        "                event_details[event.xpath('span[@class=\"name\"]/text()').extract_first()] = \\\n",
        "                re.sub(r'\\n|\\t', '', event.xpath('span[@class=\"value\"]/text()').extract_first())\n",
        "            except:\n",
        "                event_details[event.xpath('span[@class=\"name\"]/text()').extract_first()] = \\\n",
        "                event.xpath('span[@class=\"value\"]/text()').extract_first()\n",
        "            self.found_events.append(event_details)\n",
        "            \n",
        "        for event in response.xpath('//div[@class=\"vip-title clearfix\"]'):\n",
        "            event_details = dict()            \n",
        "            event_details['title'] = event.xpath('h1/span[@class=\"myAdTitle\"]/text()').extract_first()\n",
        "            self.found_events.append(event_details)\n",
        "            \n",
        "        for event in response.xpath('//div[@class=\"vip-title clearfix\"]'):\n",
        "            event_details = dict()            \n",
        "            event_details['price'] = event.xpath('div/span/span[@class=\"amount\"]/text()').extract_first()\n",
        "            self.found_events.append(event_details)\n",
        "            \n",
        "        for event in response.xpath('//div[@class=\"description\"]'):\n",
        "            event_details = dict()\n",
        "            event_details['description'] = event.xpath('span[@class=\"pre\"]/text()').extract_first()\n",
        "            self.found_events.append(event_details)\n",
        "\n",
        "process = CrawlerProcess({ 'LOG_LEVEL': 'ERROR'}) #DEBUG\n",
        "process.crawl(PythonEventsSpider)\n",
        "spider = next(iter(process.crawlers)).spider\n",
        "process.start()\n",
        "\n",
        "for event in spider.found_events: print(event)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Data dodania': '10/03/2019'}\n",
            "{'Lokalizacja': ''}\n",
            "{'Na sprzedaż przez': 'Właściciel'}\n",
            "{'Rodzaj nieruchomości': 'Mieszkanie'}\n",
            "{'Liczba pokoi': '3 pokoje'}\n",
            "{'Liczba łazienek': '1 łazienka'}\n",
            "{'Wielkość (m2)': '72'}\n",
            "{'Parking': 'Ulica'}\n",
            "{None: None}\n",
            "{'title': 'Klimatyczne mieszkanie na Pięknej'}\n",
            "{'price': '1\\xa0100\\xa0000 zł'}\n",
            "{'description': '\\r\\n\\r\\n'}\n",
            "{'description': None}\n",
            "{'description': None}\n",
            "{'description': None}\n",
            "{'description': None}\n",
            "{'description': None}\n",
            "{'description': None}\n",
            "{'description': None}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "w1lHa8m65fUg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#id oferty\n",
        "#id sprzedającego\n",
        "#nazwa sprzedającego\n",
        "#od kiedy sprzedający\n",
        "#data zaczytania\n",
        "#fotki\n",
        "#poprawić lokalizację\n",
        "#poprawić kasę"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}